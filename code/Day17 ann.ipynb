{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# worked on dataset loading, facing some bugs in displaying so will work on that\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.1+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\pande\\\\OneDrive\\\\Documents\\\\code\\\\ML\\\\ML-book-journey\\\\implementations\\\\__file__'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.abspath('__file__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformation to flatten the input tensor\n",
    "class Flatten(object):\n",
    "    def __call__(self, tensor):\n",
    "        return tensor.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1307])\n",
      "tensor([0.3052])\n"
     ]
    }
   ],
   "source": [
    "root=\"../datasets/\"\n",
    "num_images=60000\n",
    "image_dim=28*28\n",
    "\n",
    "'''without flatten'''\n",
    "transform=transforms.Compose([transforms.ToTensor(),])\n",
    "\n",
    "'''with flatten, doesnt work properly'''\n",
    "# transform=transforms.Compose([transforms.ToTensor(),transforms.Lambda(torch.flatten)])\n",
    "\n",
    "\n",
    "# Create training dataset\n",
    "train_dataset = MNIST(root=root+'MNIST_', train=True, download=True, transform=transform)\n",
    "\n",
    "# Create DataLoader for training dataset\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "channels=1\n",
    "nimages = 0\n",
    "mean = 0.0\n",
    "var = 0.0\n",
    "for i_batch, batch_target in enumerate(train_loader):\n",
    "    # print(\"ibatch\",i_batch)\n",
    "    batch = batch_target[0]\n",
    "    # print(batch.size(0),batch.size(1))\n",
    "\n",
    "    # Rearrange batch to be the shape of [B, C, W * H]\n",
    "    batch = batch.view(batch.size(0), batch.size(1), -1)\n",
    "    # print(batch.size(0),batch.size(1))\n",
    "\n",
    "    # Update total number of images\n",
    "    nimages += batch.size(0)\n",
    "    # Compute mean and std here\n",
    "    mean += batch.mean(2).sum(0) \n",
    "    var += batch.var(2).sum(0)\n",
    "\n",
    "    # print(mean)\n",
    "    # print(var)\n",
    "    # raise ZeroDivisionError\n",
    "\n",
    "mean /= nimages\n",
    "var /= nimages\n",
    "std = torch.sqrt(var)\n",
    "\n",
    "print(\"mean\",mean)\n",
    "print(\"mean\",std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=\"../datasets/\"\n",
    "num_images=60000\n",
    "image_dim=28*28\n",
    "\n",
    "# '''without flatten'''\n",
    "transform=transforms.Compose([transforms.ToTensor(),])\n",
    "\n",
    "# transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((mean,),(std,))])\n",
    "\n",
    "# Create training dataset\n",
    "train_dataset = MNIST(root=root+'MNIST_', train=True, download=True, transform=transform)\n",
    "\n",
    "# Create DataLoader for training dataset\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# Create training dataset\n",
    "test_dataset = MNIST(root=root+'MNIST_', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create DataLoader for training dataset\n",
    "batch_size = 64\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Generate a random integer tensor in the range [0, 64) of shape (2, 3)\n",
    "randint_tensor = torch.randint(low=0, high=64, size=(1,1))[0][0].item()\n",
    "print(randint_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: torch.Size([64, 1, 28, 28])\n",
      "Labels shape: torch.Size([64])\n",
      "First image in the batch:\n",
      "img is  35\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.3490, 0.8471, 1.0000, 0.5961,\n",
      "          0.2588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.2314, 0.9373, 0.9922, 0.9922, 0.9922,\n",
      "          0.9294, 0.1373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.1804, 0.9647, 0.9922, 0.9804, 0.7922, 0.9922,\n",
      "          0.9922, 0.7294, 0.0275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.1020, 0.8431, 0.9922, 0.8824, 0.1451, 0.0000, 0.6078,\n",
      "          0.9922, 0.9922, 0.4667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.7843, 0.9922, 0.7490, 0.1647, 0.0000, 0.0000, 0.0863,\n",
      "          0.9922, 0.9922, 0.4667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.4902, 0.9843, 0.8235, 0.0275, 0.0000, 0.0000, 0.0000, 0.2863,\n",
      "          0.9922, 0.9922, 0.4667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.7412, 0.9922, 0.7216, 0.0000, 0.0000, 0.0000, 0.0000, 0.7725,\n",
      "          0.9922, 0.9922, 0.3843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0588,\n",
      "          0.8275, 0.9922, 0.3804, 0.0000, 0.0000, 0.0000, 0.2784, 0.9804,\n",
      "          0.9922, 0.9922, 0.0392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1725,\n",
      "          0.9922, 0.9529, 0.0314, 0.0000, 0.0000, 0.1333, 0.8549, 0.9922,\n",
      "          0.9922, 0.8039, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1725,\n",
      "          0.9922, 0.9529, 0.0000, 0.0000, 0.1059, 0.7137, 0.9922, 0.9922,\n",
      "          0.9922, 0.6118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1098,\n",
      "          0.9020, 0.9843, 0.4549, 0.1255, 0.8549, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.6118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.7059, 0.9922, 0.9804, 0.9529, 0.9922, 0.9765, 0.7569, 0.9922,\n",
      "          0.9922, 0.6118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1098, 0.8275, 0.9922, 0.9922, 0.7804, 0.4196, 0.3647, 0.9922,\n",
      "          0.9922, 0.5098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0902, 0.1882, 0.1882, 0.0157, 0.0000, 0.3647, 0.9922,\n",
      "          0.9922, 0.3529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3647, 0.9922,\n",
      "          0.9922, 0.6118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3647, 0.9922,\n",
      "          0.9922, 0.6118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2078, 0.9686,\n",
      "          0.9922, 0.6118, 0.2196, 0.4118, 0.0745, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.9333,\n",
      "          0.9922, 0.9882, 0.9843, 0.6824, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6353,\n",
      "          0.9922, 0.9922, 0.8000, 0.0941, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3294,\n",
      "          0.9922, 0.8314, 0.0863, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "Label of the first image: tensor(6)\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(train_loader)\n",
    "data, labels = next(data_iter)\n",
    "\n",
    "# Accessing data from the batch\n",
    "print(\"Data shape:\", data.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n",
    "\n",
    "r=torch.randint(low=0, high=64, size=(1,1))[0][0].item()\n",
    "# Example: Print the first image and its label from the batch\n",
    "print(\"First image in the batch:\")\n",
    "print(\"img is \",r)\n",
    "print(data[r])  # Accessing the first image\n",
    "\n",
    "print(\"Label of the first image:\", labels[0])  # Accessing the label of the first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(m):\n\u001b[1;32m----> 5\u001b[0m         val\u001b[38;5;241m=\u001b[39m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (val\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      7\u001b[0m             val\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "img = data[0][0]\n",
    "m=28\n",
    "for i in range(m):\n",
    "    for j in range(m):\n",
    "        val=[i][j]\n",
    "        if (val>0):\n",
    "            val=\"@\"\n",
    "        else:\n",
    "            val=\".\"\n",
    "        print(val,end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Index: 5\n",
      "Data shape: torch.Size([64, 1, 28, 28])\n",
      "Labels shape: torch.Size([64])\n",
      "First image in the batch:\n",
      "tensor([[[-0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.0426, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281,  0.3685,  0.6511,  1.0365,  1.3449,  0.6511,  0.6511,\n",
      "           0.6511,  1.7046,  2.6681,  1.9744,  1.9744,  1.5633,  0.1244,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,  0.3299,\n",
      "           1.9744,  2.7581,  2.8223,  2.8223,  2.8223,  2.8223,  2.8223,\n",
      "           2.8223,  2.8223,  2.8223,  2.8223,  2.8223,  2.8223,  2.7067,\n",
      "           1.6661,  0.6383, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,  2.1029,\n",
      "           2.8223,  2.8223,  2.7324,  1.8973,  1.8973,  1.8973,  1.8973,\n",
      "           2.0900,  1.5633,  1.3192,  1.8973,  1.8973,  2.1799,  2.8223,\n",
      "           2.8223,  2.7838,  0.4070, -0.4281, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.1326,  2.4497,\n",
      "           2.8223,  1.8074, -0.0683, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.3381, -0.3381, -0.4281, -0.4281, -0.4281, -0.2996, -0.0298,\n",
      "           0.3171,  2.5268,  2.2827, -0.0683, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281,  1.0622,  2.8223,\n",
      "           2.8223,  1.2935, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281,  0.1372,  2.5397,  1.4862, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281,  1.5376,  2.8223,\n",
      "           2.8223,  1.7560, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281,  1.6404,  1.4862, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281,  2.8352,  2.8223,\n",
      "           2.0001,  1.7560, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281,  1.6404,  1.7688, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281,  2.8480,  1.3449,\n",
      "           1.3963,  2.6168,  0.3042, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.3638,  2.1029,  2.3084, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281,  2.0772,  1.0622,\n",
      "          -0.1968,  1.5761,  2.1157,  0.1501, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.2739,  2.3984,  2.8223,  2.2570, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281,  1.4990,  0.6254,\n",
      "          -0.4281, -0.1583,  2.6296,  1.0365, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.3253,\n",
      "           1.8202,  2.8223,  2.8223,  1.3449, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.0683, -0.0812,\n",
      "          -0.4281, -0.4281,  1.6917,  2.7709,  0.8438, -0.1197, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.2867,  0.5226,  0.9338,  2.5268,\n",
      "           2.8223,  2.6424,  1.2806, -0.3895, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.3253,  1.7046,  2.8223,  2.6039,  1.3577,\n",
      "           1.3577,  1.3577,  1.9102,  2.2313,  2.8223,  2.8223,  2.8223,\n",
      "           2.1543,  0.2657, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.3253,  1.6917,  2.6296,  2.8223,\n",
      "           2.8223,  2.8223,  2.8223,  2.8223,  2.7966,  1.6018,  0.5740,\n",
      "          -0.3124, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.1583,  1.2164,\n",
      "           1.9615,  1.4348,  0.6383,  0.6383,  0.5098, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281],\n",
      "         [-0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281,\n",
      "          -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281, -0.4281]]])\n",
      "Label of the first image: tensor(0)\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "    # data: tensor of shape (batch_size, channels, height, width)\n",
    "    # labels: tensor of shape (batch_size)\n",
    "    batch_idx=5\n",
    "    # Accessing data from the current batch\n",
    "    print(\"Batch Index:\", batch_idx)\n",
    "    print(\"Data shape:\", data.shape)\n",
    "    print(\"Labels shape:\", labels.shape)\n",
    "\n",
    "    # Example: Print the first image and its label from the batch\n",
    "    print(\"First image in the batch:\")\n",
    "    print(data[0])  # Accessing the first image\n",
    "    print(\"Label of the first image:\", labels[0])  # Accessing the label of the first image\n",
    "\n",
    "    # Accessing multiple images and labels from the batch\n",
    "    for i in range(5):  # Accessing the first 5 images in the batch\n",
    "        image = data[i]\n",
    "        label = labels[i]\n",
    "        # Process the image and label as needed\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
